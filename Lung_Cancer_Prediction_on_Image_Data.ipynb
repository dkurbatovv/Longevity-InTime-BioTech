{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Lung Cancer Prediction on Image Data",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1oRld2ixaR57mjErb2xijrGb4QjNUkgQe",
      "authorship_tag": "ABX9TyOj7Eavs/OgHRKakadhpAy7",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dkurbatovv/Longevity-InTime-BioTech/blob/main/Lung_Cancer_Prediction_on_Image_Data.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# *Loading data*"
      ],
      "metadata": {
        "id": "xJ8B4UvNxdA5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qjQWA7SHnX4l"
      },
      "outputs": [],
      "source": [
        "!pip install kaggle\n",
        "from google.colab import files\n",
        "\n",
        "uploaded = files.upload()\n",
        "\n",
        "for fn in uploaded.keys():\n",
        "  print('User uploaded file \"{name}\" with length {length} bytes'.format(\n",
        "      name=fn, length=len(uploaded[fn])))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p ~/.kaggle/\n",
        "! cp kaggle.json ~/.kaggle/\n",
        "! chmod 600 ~/.kaggle/kaggle.json"
      ],
      "metadata": {
        "id": "05Xzz9k1np3W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! kaggle datasets download -d adityamahimkar/iqothnccd-lung-cancer-dataset"
      ],
      "metadata": {
        "id": "O0PIijC6n2Ib"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! unzip iqothnccd-lung-cancer-dataset.zip"
      ],
      "metadata": {
        "id": "Ki0u0cDsn-Yu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# *Import libraries and images*"
      ],
      "metadata": {
        "id": "y-lM9eXexieQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%config Completer.use_jedi = False\n",
        "import numpy as np \n",
        "import pandas as pd \n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import cv2\n",
        "import random\n",
        "import os\n",
        "import imageio\n",
        "\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from collections import Counter\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, recall_score, precision_score, classification_report, confusion_matrix, plot_confusion_matrix\n",
        "from sklearn.model_selection import RandomizedSearchCV, cross_val_score, RepeatedStratifiedKFold\n",
        "\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "from keras.models import Sequential, Model \n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.layers import Conv2D, Dense, Input, MaxPooling2D, Flatten, BatchNormalization, Concatenate, Reshape,Dropout\n",
        "from keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array, array_to_img"
      ],
      "metadata": {
        "id": "pFOJ7N5CoDWz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "directory = r'/content/The IQ-OTHNCCD lung cancer dataset/The IQ-OTHNCCD lung cancer dataset'\n",
        "\n",
        "categories = ['Bengin cases', 'Malignant cases', 'Normal cases']"
      ],
      "metadata": {
        "id": "poT8wEhnorXf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "size_data = {}\n",
        "\n",
        "\n",
        "for i in categories:\n",
        "    path = os.path.join(directory, i)\n",
        "    class_num = categories.index(i)\n",
        "    categories_dict = {}\n",
        "\n",
        "    for file in os.listdir(path):\n",
        "        filepath = os.path.join(path, file)\n",
        "        height, width, channels = imageio.imread(filepath).shape\n",
        "        if str(height) + ' x ' + str(width) in categories_dict:\n",
        "            categories_dict[str(height) + ' x ' + str(width)] += 1 \n",
        "        else:\n",
        "            categories_dict[str(height) + ' x ' + str(width)] = 1\n",
        "    \n",
        "    size_data[i] = categories_dict\n",
        "        \n",
        "size_data"
      ],
      "metadata": {
        "id": "6Ukc2jbsowM9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in categories:\n",
        "    path = os.path.join(directory, i)\n",
        "    class_num = categories.index(i)\n",
        "    for file in os.listdir(path):\n",
        "        filepath = os.path.join(path, file)\n",
        "        print(i)\n",
        "        img = cv2.imread(filepath, 0)\n",
        "        plt.imshow(img)\n",
        "        plt.show()\n",
        "        break"
      ],
      "metadata": {
        "id": "KmClt_wOo3w1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# *Image Preprocessing*"
      ],
      "metadata": {
        "id": "RMGLLEILpadz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "img_size = 256\n",
        "for i in categories:\n",
        "    cnt, samples = 0, 3\n",
        "    fig, ax = plt.subplots(samples, 3, figsize=(15, 15))\n",
        "    fig.suptitle(i)\n",
        "    \n",
        "    path = os.path.join(directory, i)\n",
        "    class_num = categories.index(i)\n",
        "    for curr_cnt, file in enumerate(os.listdir(path)):\n",
        "        filepath = os.path.join(path, file)\n",
        "        img = cv2.imread(filepath, 0)\n",
        "        \n",
        "        img0 = cv2.resize(img, (img_size, img_size))\n",
        "        \n",
        "        img1 = cv2.GaussianBlur(img0, (5, 5), 0)\n",
        "        \n",
        "        ax[cnt, 0].imshow(img)\n",
        "        ax[cnt, 1].imshow(img0)\n",
        "        ax[cnt, 2].imshow(img1)\n",
        "        cnt += 1\n",
        "        if cnt == samples:\n",
        "            break\n",
        "        \n",
        "plt.show() "
      ],
      "metadata": {
        "id": "rt6l66yEpG8x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = []\n",
        "img_size = 256\n",
        "\n",
        "for i in categories:\n",
        "    path = os.path.join(directory, i)\n",
        "    class_num = categories.index(i)\n",
        "    for file in os.listdir(path):\n",
        "        filepath = os.path.join(path, file)\n",
        "        img = cv2.imread(filepath, 0)\n",
        "        # preprocess here\n",
        "        img = cv2.resize(img, (img_size, img_size))\n",
        "        data.append([img, class_num])\n",
        "        \n",
        "random.shuffle(data)\n",
        "\n",
        "X, y = [], []\n",
        "for feature, label in data:\n",
        "    X.append(feature)\n",
        "    y.append(label)\n",
        "    "
      ],
      "metadata": {
        "id": "aAWyjCbLpjuR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# normalize\n",
        "X = np.array(X).reshape(-1, img_size, img_size, 1)\n",
        "X = X / 255.0\n",
        "y = np.array(y)"
      ],
      "metadata": {
        "id": "UKVto0jOp2hG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_valid, y_train, y_valid = train_test_split(X, y, random_state=10, stratify=y)"
      ],
      "metadata": {
        "id": "nwYa24DbrT7X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = X_train.reshape(X_train.shape[0], img_size*img_size*1)"
      ],
      "metadata": {
        "id": "p5C1lS8jrVwZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Before SMOTE:', Counter(y_train))\n",
        "smote = SMOTE()\n",
        "X_train_sampled, y_train_sampled = smote.fit_resample(X_train, y_train)\n",
        "print('After SMOTE:', Counter(y_train_sampled))"
      ],
      "metadata": {
        "id": "jWjN8990rgOs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = X_train.reshape(X_train.shape[0], img_size, img_size, 1)\n",
        "X_train_sampled = X_train_sampled.reshape(X_train_sampled.shape[0], img_size, img_size, 1)\n",
        "\n",
        "print(len(X_train), X_train.shape)\n",
        "print(len(X_train_sampled), X_train_sampled.shape)"
      ],
      "metadata": {
        "id": "Ch9KW9Grrhy8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# *Model building*"
      ],
      "metadata": {
        "id": "G22sBirIw3Ai"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "\n",
        "model.add(Conv2D(32, (3, 3), input_shape=X_train.shape[1:], activation='relu'))\n",
        "model.add(Conv2D(32, (3, 3), activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.4))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128))\n",
        "model.add(Dropout(0.6))\n",
        "model.add(Dense(3, activation='softmax'))\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "aYn0Elztrk_Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "T9yeaQD4sLAv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# *Model training*"
      ],
      "metadata": {
        "id": "FFilAhLzxEIY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(X_train_sampled, y_train_sampled, batch_size=8, epochs=10, validation_data=(X_valid, y_valid))"
      ],
      "metadata": {
        "id": "44SJUeu3sPlP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = model.predict(X_valid, verbose=1)\n",
        "y_pred_bool = np.argmax(y_pred, axis=1)\n",
        "\n",
        "print(classification_report(y_valid, y_pred_bool))\n",
        "\n",
        "print(confusion_matrix(y_true=y_valid, y_pred=y_pred_bool))"
      ],
      "metadata": {
        "id": "CKonKoBEsRbo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# *Displaying results on a chart*"
      ],
      "metadata": {
        "id": "dLQQGQMNxMCh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(history.history['accuracy'], label='Train')\n",
        "plt.plot(history.history['val_accuracy'], label='Validation')\n",
        "plt.title('Model Accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "plt.plot(history.history['loss'], label='Train')\n",
        "plt.plot(history.history['val_loss'], label='Validation')\n",
        "plt.title('Model Loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "JIGxLmvhRuBh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "C5mnw_kERxkP"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}